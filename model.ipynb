{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEzToagrfh5r",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from shutil import copyfile\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UQV6ro3Vfh5y",
    "outputId": "8901a5a4-fe81-4de9-bfff-1ede1804235e"
   },
   "outputs": [],
   "source": [
    "! pip install plot_keras_history silence_tensorflow\n",
    "from plot_keras_history import plot_history\n",
    "#import silence_tensorflow.auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOOXx8Nhfh5w"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, Activation, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ( \n",
    "    EarlyStopping, \n",
    "    ReduceLROnPlateau, \n",
    "    ModelCheckpoint, \n",
    "    BaseLogger, \n",
    "    TerminateOnNaN,\n",
    ")\n",
    "from tensorflow.keras.metrics import AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cudnn fails to initialize if we don't include the following cell `¯\\_(ツ)_/¯`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWkrCuh9fh50"
   },
   "source": [
    "# Download and unzip the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ruLwbBFWfh50"
   },
   "outputs": [],
   "source": [
    "#! curl -L -o \"archive.zip\" \"https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/23921/1664239/bundle/archive.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1605518469&Signature=WdCw3%2FNSWvK2uzLV7mPLRwsz3JM5cnC3kAOc3%2BDqILc3sdWW%2BqmFcwuVSBHA3wACn4%2Fxa5LaheDYQRQHg58T2YjPw7IbtiuUUY2RUKYRB1xsY7VUzP2LocsA%2F63QRbYhwGFTzGm9ExyZA8axnUHVzbs9TZ5sJXXQnj0u4cbBEPt%2FFSbnJ6C971LlJhXRk%2F5124kMjtyH1ps4o%2BLmmcmYZ7E838Fb7yP9WL3whXIKpT9pSrR2Sgk3%2FGrj727wjwswK75mNfJv9fZWfMA1dgJiogmmW1ijLyGZ1woGCG49k5npf%2FtHdtcf40BKHX1KiDOQko4HTevbnseSquQ%2FOqpvqA%3D%3D&response-content-disposition=attachment%3B+filename%3Dartificial-neural-networks-and-deep-learning-2020.zip\" 2>1 > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bdNygQ1sknrQ"
   },
   "outputs": [],
   "source": [
    "#! unzip archive.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-poaCuKkLMQ",
    "outputId": "d139f909-6d89-470c-9e2d-ce542e9173b7"
   },
   "outputs": [],
   "source": [
    "#! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8hM6OIUkMo0"
   },
   "source": [
    "# Hyper-parameters and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qv_JfGkGfh52"
   },
   "outputs": [],
   "source": [
    "SEED = 0xc0febabe\n",
    "BATCHSIZE = 16\n",
    "IMAGE_SHAPE = (256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINTS_FOLDER = \"./weights/checkpoints_{}/\".format(SEED)\n",
    "PROCESSED_IMAGES_FOLDER = \"./SPLIT_{}\".format(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EioFriFxfh54"
   },
   "outputs": [],
   "source": [
    "# Create the folders\n",
    "_ = list(map(\n",
    "    lambda folder: os.makedirs(folder, exist_ok=True), \n",
    "    [CHECKPOINTS_FOLDER, PROCESSED_IMAGES_FOLDER]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DOM4sAvZfh56"
   },
   "outputs": [],
   "source": [
    "# set the seeds for reproducibility\n",
    "tf.random.set_seed(SEED) \n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ZAQ3jdYfh56"
   },
   "source": [
    "# Setup the validation by splitting the data in sub-folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NowdLaBKfh59"
   },
   "source": [
    "Label -> folder dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iiwkjyzfh5_"
   },
   "outputs": [],
   "source": [
    "labels_dir = {\n",
    "    0:\"0_NO_PERSON\",\n",
    "    1:\"1_ALL_THE_PEOPLE\",\n",
    "    2:\"2_SOMEONE\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./MaskDataset/train_gt.json\") as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use a stratified shuffle split to have a 90-10 split which matains the balancing of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = np.array(list(labels.items()))\n",
    "sss = StratifiedShuffleSplit(test_size=0.1, random_state=SEED)\n",
    "train_indices, val_indices = next(sss.split(labels_list[:, 0], labels_list[:, 1]))\n",
    "train_files, train_labels = labels_list[train_indices][:, 0], labels_list[train_indices][:, 1]\n",
    "val_files, val_labels = labels_list[val_indices][:, 0], labels_list[val_indices][:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAxv9Sbsfh6C"
   },
   "source": [
    "Copy the files in folders based on their label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(files, labels, dst_folder):\n",
    "    for file_name, label in tqdm(zip(files, labels), leave=False):\n",
    "        file = os.path.join(\"./MaskDataset/training/\", file_name)\n",
    "        label = labels_dir[int(label)]\n",
    "        dst_file = os.path.join(\n",
    "            dst_folder,\n",
    "            label,\n",
    "            file_name\n",
    "        )\n",
    "        os.makedirs(os.path.dirname(dst_file), exist_ok=True)\n",
    "        copyfile(file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(PROCESSED_IMAGES_FOLDER, \"train\")\n",
    "val_folder = os.path.join(PROCESSED_IMAGES_FOLDER, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder, val_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QgrrCvyyfh59"
   },
   "outputs": [],
   "source": [
    "process(\n",
    "    train_files,\n",
    "    train_labels,\n",
    "    train_folder\n",
    ")\n",
    "process(\n",
    "    val_files,\n",
    "    val_labels,\n",
    "    val_folder\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf2kFEK7fh6E"
   },
   "source": [
    "Create a dataset with the images and augment them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_func(img):\n",
    "    img = tf.image.random_saturation(img, 0.8, 1.2)\n",
    "    img = tf.image.random_hue(img, 0.1)\n",
    "    img = tf.image.random_contrast(img, 0.8, 1.2)\n",
    "    img = tf.image.random_brightness(img, 0.2)\n",
    "    return img\n",
    "\n",
    "train_data_gen = ImageDataGenerator(\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.25,\n",
    "        height_shift_range=0.25,\n",
    "        zoom_range=0.1, \n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='constant',\n",
    "        rescale=1./255,\n",
    "        preprocessing_function=preprocess_func\n",
    "    )\n",
    "    \n",
    "train_gen = train_data_gen.flow_from_directory(\n",
    "    train_folder,\n",
    "    batch_size=BATCHSIZE,\n",
    "    target_size=IMAGE_SHAPE[:-1],\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    ")\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: train_gen,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, *IMAGE_SHAPE], [None, len(labels_dir)])\n",
    ").prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "val_gen = val_data_gen.flow_from_directory(\n",
    "    val_folder,\n",
    "    batch_size=BATCHSIZE,\n",
    "    target_size=IMAGE_SHAPE[:-1],\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    seed=SEED\n",
    ")\n",
    "    \n",
    "val_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: val_gen,\n",
    "    output_types=(tf.float32, tf.float32),\n",
    "    output_shapes=([None, *IMAGE_SHAPE], [None, 3])\n",
    ").prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qO3ceQExfh6K"
   },
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsPJAYasfh6O"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "\n",
    "truncated = InceptionResNetV2(\n",
    "    input_shape=IMAGE_SHAPE, \n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = truncated.input\n",
    "h = truncated.output\n",
    "\n",
    "h = Flatten()(h)\n",
    "h = Dense(100, activation=\"linear\", \n",
    "    kernel_initializer=tf.keras.initializers.GlorotNormal()\n",
    ")(h)\n",
    "h = Dropout(0.5)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation(\"relu\")(h)\n",
    "h = Dense(10, activation=\"linear\", \n",
    "    kernel_initializer=tf.keras.initializers.GlorotNormal()\n",
    ")(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation(\"relu\")(h)\n",
    "h = Dropout(0.2)(h)\n",
    "output = Dense(3, activation=\"softmax\", \n",
    "    kernel_initializer=tf.keras.initializers.GlorotNormal()\n",
    ")(h)\n",
    "\n",
    "model = Model(i, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4YAMrUhJfh6Q",
    "outputId": "3ffa5caa-1074-46e5-d494-9440dcbd71cc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "#plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8nqYl_wafh6S"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=\"nadam\",\n",
    "    metrics=[\n",
    "        \"accuracy\",\n",
    "        AUC(curve=\"PR\", name=\"AUPRC\", multi_label=True),\n",
    "        AUC(curve=\"ROC\", name=\"AUROC\", multi_label=True),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3-UbMktfh6T",
    "outputId": "a906ae02-0d3d-4fee-e392-903edafe0bf3",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoints_folder = os.path.join(\n",
    "    CHECKPOINTS_FOLDER,\n",
    "    datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    ")\n",
    "os.makedirs(checkpoints_folder, exist_ok=True)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=1,\n",
    "    steps_per_epoch=512,\n",
    "    validation_steps=16,\n",
    "    callbacks=[\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0.001,\n",
    "            patience=20,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\",\n",
    "            min_delta=0.001,\n",
    "            patience=5,\n",
    "            factor=0.1,\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            checkpoints_folder,\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"max\",\n",
    "            save_weights_only=True\n",
    "        ),\n",
    "        TerminateOnNaN(),\n",
    "    ]\n",
    "    \n",
    ").history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-eOFD7lYfh6V"
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we save the weighs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhE5C1V_fh6X"
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"validation_final.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and evaluate the final performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_dataset, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_dataset, steps=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "keys = []\n",
    "imgs = []\n",
    "\n",
    "for file in tqdm(glob(\"./MaskDataset/test/*\"), leave=False):\n",
    "    key = os.path.basename(file)\n",
    "    keys.append(key)\n",
    "    img = Image.open(file).convert('RGB').resize(IMAGE_SHAPE[:-1])\n",
    "    img = np.array(img).reshape(1, *IMAGE_SHAPE)/255.0\n",
    "    imgs.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(np.vstack(imgs), batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.argmax(prediction, axis=1)\n",
    "result = list(zip(keys, label))    \n",
    "\n",
    "df = pd.DataFrame(result, columns=[\"Id\", \"Category\"])\n",
    "df = df.set_index(\"Id\")\n",
    "df.to_csv(\"predictions_NUOVE.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train the model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
